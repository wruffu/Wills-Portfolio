{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c4e44-6f8c-4e98-b201-27e8cc35427c",
   "metadata": {},
   "source": [
    "In this notebook, I will show how to use the Keras library to build convolutional neural networks. I will use the popular MNIST dataset and will compare results to using a conventional neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af36d5-c39c-4db1-9abf-e6ae24b6d429",
   "metadata": {},
   "source": [
    "Objectives:\n",
    ">\n",
    "1. How to use the Keras library to build convolutional neural networks.\n",
    "2. Convolutional Neural Network with One Convolutional and Pooling Layers.\n",
    "3. Convolutional Neural Network with Two Convolutional and Pooling Layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145693f-77be-4698-9305-933d6541bed9",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "      \n",
    "1. <a href=\"#item41\">Import Keras and Packages</a>   \n",
    "2. <a href=\"#item42\">Convolutional Neural Network with One Convolutional and Pooling Layers</a>  \n",
    "3. <a href=\"#item43\">Convolutional Neural Network with Two Convolutional and Pooling Layers</a>  \n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f28727-1324-4544-86e8-5dc44e72cc9e",
   "metadata": {},
   "source": [
    "<a id='item41'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a9901-1ad1-44e2-8d7c-6abbc1d4c5fa",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4daa2c1-9de3-406c-8e5b-192095c7899a",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f754a0a-5333-4ac6-b3db-8571b16421c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.21.4\n",
    "#pip install pandas==1.3.4\n",
    "#pip install keras==2.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf13643-fbbb-4805-bca7-e7058b620f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe4f53-8aba-4207-a65b-cc86be6ab692",
   "metadata": {},
   "source": [
    "When working with convolutional neural networks in particular, we will need additional packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D # to add convolutional layers\n",
    "from keras.layers import MaxPooling2D # to add pooling layers\n",
    "from keras.layers import Flatten # to flatten data for fully connected layers\n",
    "from keras.layers import MaxPooling2D # to add pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bec1ed-fae8-4523-9400-03f259b83118",
   "metadata": {},
   "source": [
    "<a id='item42'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c6d4d-4199-4ac3-86fd-83d0af27b76b",
   "metadata": {},
   "source": [
    "## Convolutional Layer with One set of convolutional and pooling layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b926053-ed83-4419-9df6-bbafcfc7f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bfc804-4b7e-4ce6-b5e8-3ddab966108d",
   "metadata": {},
   "source": [
    "Next is to normalize the pixel values to be between 0 and 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cd56d94-762f-4a2b-8116-6f04313c5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255 # normalize training data\n",
    "X_test = X_test / 255 # normalize test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10086d-2c0e-481e-b136-47ce17d7bd47",
   "metadata": {},
   "source": [
    "Next, I'll convert the target variable into binary categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a368493-3d57-47f8-a735-7807ba675e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a494f7-8bb2-4971-a5b7-a8d17b391958",
   "metadata": {},
   "source": [
    "Next, I'll define a function that creates our model. Let's start with one set of convolutional and pooling layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "762b15ce-04b4-4b52-91f4-5531b095adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd9352-8259-49e2-ac90-810ed08838f4",
   "metadata": {},
   "source": [
    "Finally, let's call the function to create the model, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc53a31-62d6-4bbc-b622-2c22b7e45c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\willl\\OneDrive\\Desktop\\My_Documents\\Wills_Py_Folder\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 - 2s - 7ms/step - accuracy: 0.9188 - loss: 0.2938 - val_accuracy: 0.9696 - val_loss: 0.1042\n",
      "Epoch 2/10\n",
      "300/300 - 1s - 4ms/step - accuracy: 0.9732 - loss: 0.0920 - val_accuracy: 0.9766 - val_loss: 0.0727\n",
      "Epoch 3/10\n",
      "300/300 - 1s - 4ms/step - accuracy: 0.9814 - loss: 0.0617 - val_accuracy: 0.9841 - val_loss: 0.0511\n",
      "Epoch 4/10\n",
      "300/300 - 1s - 4ms/step - accuracy: 0.9857 - loss: 0.0473 - val_accuracy: 0.9851 - val_loss: 0.0443\n",
      "Epoch 5/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9890 - loss: 0.0374 - val_accuracy: 0.9868 - val_loss: 0.0404\n",
      "Epoch 6/10\n",
      "300/300 - 2s - 7ms/step - accuracy: 0.9908 - loss: 0.0308 - val_accuracy: 0.9858 - val_loss: 0.0401\n",
      "Epoch 7/10\n",
      "300/300 - 2s - 7ms/step - accuracy: 0.9924 - loss: 0.0258 - val_accuracy: 0.9870 - val_loss: 0.0376\n",
      "Epoch 8/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9930 - loss: 0.0229 - val_accuracy: 0.9890 - val_loss: 0.0355\n",
      "Epoch 9/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9940 - loss: 0.0196 - val_accuracy: 0.9865 - val_loss: 0.0403\n",
      "Epoch 10/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9950 - loss: 0.0169 - val_accuracy: 0.9878 - val_loss: 0.0386\n",
      "Accuracy: 0.9878000020980835 \n",
      " Error: 1.2199997901916504\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda50d4-2b28-4a03-95d3-a78f6e289992",
   "metadata": {},
   "source": [
    "------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4bcd75-801e-4ccb-b268-a35d3249d39c",
   "metadata": {},
   "source": [
    "<a id='item43'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc665a-cf08-4b37-93e9-51b24a3c5f65",
   "metadata": {},
   "source": [
    "## Convolutional Layer with two sets of convolutional and pooling layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89123c1f-18ba-402b-8d14-83ed04bac39a",
   "metadata": {},
   "source": [
    "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4b3fb97-94a5-421b-80c1-8c4fe4134eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e1050d-e6b1-4a7e-a028-273b119dcc68",
   "metadata": {},
   "source": [
    "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c9020f2-a385-4ba5-9923-7fa42be5dd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 3s - 9ms/step - accuracy: 0.8605 - loss: 0.4849 - val_accuracy: 0.9542 - val_loss: 0.1554\n",
      "Epoch 2/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9625 - loss: 0.1275 - val_accuracy: 0.9679 - val_loss: 0.1025\n",
      "Epoch 3/10\n",
      "300/300 - 2s - 5ms/step - accuracy: 0.9732 - loss: 0.0891 - val_accuracy: 0.9799 - val_loss: 0.0645\n",
      "Epoch 4/10\n",
      "300/300 - 2s - 5ms/step - accuracy: 0.9788 - loss: 0.0708 - val_accuracy: 0.9825 - val_loss: 0.0552\n",
      "Epoch 5/10\n",
      "300/300 - 2s - 5ms/step - accuracy: 0.9814 - loss: 0.0607 - val_accuracy: 0.9854 - val_loss: 0.0457\n",
      "Epoch 6/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9841 - loss: 0.0521 - val_accuracy: 0.9847 - val_loss: 0.0463\n",
      "Epoch 7/10\n",
      "300/300 - 2s - 5ms/step - accuracy: 0.9858 - loss: 0.0457 - val_accuracy: 0.9858 - val_loss: 0.0475\n",
      "Epoch 8/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9870 - loss: 0.0411 - val_accuracy: 0.9867 - val_loss: 0.0404\n",
      "Epoch 9/10\n",
      "300/300 - 2s - 5ms/step - accuracy: 0.9887 - loss: 0.0364 - val_accuracy: 0.9888 - val_loss: 0.0343\n",
      "Epoch 10/10\n",
      "300/300 - 2s - 6ms/step - accuracy: 0.9897 - loss: 0.0333 - val_accuracy: 0.9856 - val_loss: 0.0418\n",
      "Accuracy: 0.9855999946594238 \n",
      " Error: 1.4400005340576172\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we explored Convolutional Neural Networks (CNNs) using Keras to classify the MNIST handwritten digit dataset. We covered several key concepts and processes:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "    - Loaded and reshaped the MNIST data to fit the CNN input requirements\n",
    "    - Normalized pixel values to a 0-1 range\n",
    "    - Converted target variables to categorical format using one-hot encoding\n",
    "\n",
    "2. **CNN Architectures**:\n",
    "    - Built a simple CNN with one convolutional and pooling layer\n",
    "    - Created a more complex CNN with two sets of convolutional and pooling layers\n",
    "    - Used the Sequential model API from Keras for model construction\n",
    "\n",
    "3. **Key Components**:\n",
    "    - Convolutional layers (Conv2D) to extract features from images\n",
    "    - MaxPooling2D layers to reduce dimensionality\n",
    "    - Flatten layer to convert 2D feature maps to 1D feature vectors\n",
    "    - Dense layers for classification\n",
    "\n",
    "4. **Training and Evaluation**:\n",
    "    - Trained models for 10 epochs using categorical cross-entropy loss\n",
    "    - Used Adam optimizer for gradient descent\n",
    "    - Evaluated model performance using accuracy metrics\n",
    "\n",
    "This approach has numerous business applications:\n",
    "- Document processing and optical character recognition (OCR)\n",
    "- Quality control in manufacturing (defect detection)\n",
    "- Medical image analysis and diagnosis\n",
    "- Facial recognition systems\n",
    "- Self-driving vehicles and object detection\n",
    "- Retail inventory management through image recognition\n",
    "\n",
    "The techniques demonstrated here can be extended to more complex image classification problems by adjusting the network architecture, adding more layers, or using transfer learning with pre-trained models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
